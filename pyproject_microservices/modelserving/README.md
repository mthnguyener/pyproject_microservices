#  Model Serving
   - Deploys and serves trained models.
   - Uses containerization (e.g., Docker) for model deployment.
   - Note: Can be combined with `Model Inference` for simplicity and reduced latency
